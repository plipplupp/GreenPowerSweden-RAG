{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deceb514",
   "metadata": {},
   "source": [
    "### PDF-analys (Text vs. OCR) - för att avgöra om en pdf är textbaserad eller skannade bilder (som kommer kräva OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd11c8",
   "metadata": {},
   "source": [
    "### Importera bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468e1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm  # För en snygg progress bar i notebooken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c3c44",
   "metadata": {},
   "source": [
    "### Sätt upp sökvägar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e6c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(r\"C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "# VIKTIGT: Vi pekar nu på den RIKTIGA, städade mappen\n",
    "CLEAN_DATA_DIR = DATA_DIR / \"01_raw\"\n",
    "# TEST_DATA_DIR = DATA_DIR / \"00_test\"\n",
    "\n",
    "# Mapp för att spara bearbetade filer (enligt filstrukturen)\n",
    "PROCESSED_DIR = DATA_DIR / \"02_processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Filen där vi sparar vår analys-rapport\n",
    "ANALYSIS_RESULT_FILE = PROCESSED_DIR / \"pdf_analysis_report.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317c9a7",
   "metadata": {},
   "source": [
    "### Hitta NYA PDF-filer att analysera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead17394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hittade en befintlig rapport med 3617 analyserade filer.\n",
      "Söker efter ALLA PDF-filer i: C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\\data\\01_raw...\n",
      "Hittade totalt 4502 PDF-filer på disken.\n",
      "\n",
      "--- Analys-sammanfattning ---\n",
      "Totalt antal filer på disk: 4502\n",
      "Filer redan analyserade:   3617\n",
      "NYA filer att analysera:    885\n",
      "Rensade bort 0 borttagna filer från rapporten.\n"
     ]
    }
   ],
   "source": [
    "# Vi laddar den befintliga rapporten för att se vilka filer vi redan har analyserat.\n",
    "\n",
    "# Läs den BEFINTLIGA rapporten, om den finns\n",
    "try:\n",
    "    df_existing = pd.read_csv(ANALYSIS_RESULT_FILE)\n",
    "    # Skapa en 'set' (uppsättning) av alla filvägar vi redan känner till\n",
    "    # Vi måste normalisera sökvägarna för att jämförelsen ska fungera\n",
    "    seen_files = set(df_existing['full_path'].apply(lambda x: str(Path(x))))\n",
    "    print(f\"Hittade en befintlig rapport med {len(seen_files)} analyserade filer.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Ingen befintlig rapport hittades. Startar en ny analys.\")\n",
    "    df_existing = pd.DataFrame(columns=[\"full_path\", \"status\", \"chars_page_1\", \"total_pages\", \"filename\"]) # Skapa tom\n",
    "    seen_files = set()\n",
    "\n",
    "# Hämta ALLA PDF-filer som finns på disk NU\n",
    "print(f\"Söker efter ALLA PDF-filer i: {CLEAN_DATA_DIR}...\")\n",
    "all_pdf_files = list(CLEAN_DATA_DIR.rglob(\"*.pdf\"))\n",
    "print(f\"Hittade totalt {len(all_pdf_files)} PDF-filer på disken.\")\n",
    "\n",
    "# Jämför och hitta de som är NYA\n",
    "files_to_analyze = []\n",
    "for file_path in all_pdf_files:\n",
    "    # Normalisera sökvägen även här\n",
    "    normalized_path = str(file_path)\n",
    "    if normalized_path not in seen_files:\n",
    "        files_to_analyze.append(file_path)\n",
    "\n",
    "print(f\"\\n--- Analys-sammanfattning ---\")\n",
    "print(f\"Totalt antal filer på disk: {len(all_pdf_files)}\")\n",
    "print(f\"Filer redan analyserade:   {len(seen_files)}\")\n",
    "print(f\"NYA filer att analysera:    {len(files_to_analyze)}\")\n",
    "\n",
    "# Kontroll: Vi behöver också se om filer har tagits bort\n",
    "existing_paths_on_disk = set(str(p) for p in all_pdf_files)\n",
    "df_existing = df_existing[df_existing['full_path'].apply(lambda x: str(Path(x)) in existing_paths_on_disk)]\n",
    "print(f\"Rensade bort {len(seen_files) - len(df_existing)} borttagna filer från rapporten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4a034",
   "metadata": {},
   "source": [
    "### Hämtar alla pdf-filer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8c1b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Söker efter PDF-filer i: C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\\data\\01_raw...\n",
      "Hittade 4502 PDF-filer att analysera.\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Söker efter PDF-filer i: {TEST_DATA_DIR}...\")\n",
    "# pdf_files = list(TEST_DATA_DIR.rglob(\"*.pdf\"))\n",
    "# print(f\"Hittade {len(pdf_files)} PDF-filer att analysera.\")\n",
    "\n",
    "print(f\"Söker efter PDF-filer i: {CLEAN_DATA_DIR}...\")\n",
    "pdf_files = list(CLEAN_DATA_DIR.rglob(\"*.pdf\"))\n",
    "print(f\"Hittade {len(pdf_files)} PDF-filer att analysera.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2f39c",
   "metadata": {},
   "source": [
    "#### Skapa Analysfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0a21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Den här funktionen öppnar en PDF, försöker extrahera text från *första sidan*, och räknar antalet tecken.\n",
    "\n",
    "# **Vår logik (heuristik):**\n",
    "# * Om första sidan har > 50 tecken, antar vi att den är **textbaserad**.\n",
    "# * Om första sidan har < 50 tecken, är den en **OCR-kandidat**.\n",
    "\n",
    "def analyze_pdf_type(file_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Analyserar en enskild PDF och returnerar dess typ.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            \n",
    "            # Kontrollera om PDF:en har några sidor alls\n",
    "            if not pdf.pages:\n",
    "                return {\"status\": \"error_no_pages\", \"chars_page_1\": 0, \"total_pages\": 0}\n",
    "            \n",
    "            # Hämta första sidan\n",
    "            first_page = pdf.pages[0]\n",
    "            \n",
    "            # Försök extrahera text\n",
    "            text = first_page.extract_text()\n",
    "            \n",
    "            # Räkna antalet \"rena\" tecken\n",
    "            char_count = 0\n",
    "            if text:\n",
    "                char_count = len(text.strip())\n",
    "            \n",
    "            total_pages = len(pdf.pages)\n",
    "\n",
    "            if char_count > 50:\n",
    "                # Troligen en text-baserad PDF\n",
    "                return {\"status\": \"text_based\", \"chars_page_1\": char_count, \"total_pages\": total_pages}\n",
    "            else:\n",
    "                # Troligen en skannad bild (eller en PDF med bara bilder)\n",
    "                return {\"status\": \"ocr_candidate\", \"chars_page_1\": char_count, \"total_pages\": total_pages}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Hantera korrupta eller lösenordsskyddade filer\n",
    "        return {\"status\": f\"error_{type(e).__name__}\", \"chars_page_1\": 0, \"total_pages\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82347069",
   "metadata": {},
   "source": [
    "### Kör analysfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5780cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startar analys av 885 nya filer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93e857ce3f144c1bc02b24c7e6b593d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyserar NYA PDF-filer:   0%|          | 0/885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analys av nya filer klar.\n"
     ]
    }
   ],
   "source": [
    "# Nu loopar bara igenom nya filer (`files_to_analyze`) och analyserar dem\n",
    "\n",
    "analysis_results = []\n",
    "\n",
    "new_analysis_results = [] # Nytt namn för tydlighet\n",
    "\n",
    "if files_to_analyze: # Kör bara om det finns något att göra\n",
    "    print(f\"Startar analys av {len(files_to_analyze)} nya filer...\")\n",
    "    # tqdm ger oss en fin progress bar\n",
    "    for file in tqdm(files_to_analyze, desc=\"Analyserar NYA PDF-filer\"):\n",
    "        result = analyze_pdf_type(file)\n",
    "        result[\"full_path\"] = str(file) # Lägg till sökvägen i resultatet\n",
    "        result[\"filename\"] = file.name\n",
    "        new_analysis_results.append(result)\n",
    "\n",
    "    print(\"Analys av nya filer klar.\")\n",
    "else:\n",
    "    print(\"Inga nya filer att analysera. Allt är uppdaterat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f367ba1",
   "metadata": {},
   "source": [
    "### Granska resultat och spara till fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea185fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sammanfattning av TOTAL PDF-analys (Gamla + Nya) ---\n",
      "status\n",
      "text_based       4372\n",
      "ocr_candidate     130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Exempel på data (från nya filer om några fanns) ---\n",
      "       status  chars_page_1  total_pages  \\\n",
      "0  text_based           769            8   \n",
      "1  text_based           963           22   \n",
      "2  text_based          1110           33   \n",
      "3  text_based           900           10   \n",
      "4  text_based           726           20   \n",
      "\n",
      "                                           full_path  \\\n",
      "0  C:\\Users\\Dator\\Documents\\Data_Science\\11_Exame...   \n",
      "1  C:\\Users\\Dator\\Documents\\Data_Science\\11_Exame...   \n",
      "2  C:\\Users\\Dator\\Documents\\Data_Science\\11_Exame...   \n",
      "3  C:\\Users\\Dator\\Documents\\Data_Science\\11_Exame...   \n",
      "4  C:\\Users\\Dator\\Documents\\Data_Science\\11_Exame...   \n",
      "\n",
      "                                            filename  \n",
      "0      FÖRVR_2010-10-22_6720-10_bygglov och 12_6.PDF  \n",
      "1  MMD_2023-03-21_M3143-22_föreläggande enligt KM...  \n",
      "2  MMD_2024-11-07_M4815-23_tidsrestriktion 2 år m...  \n",
      "3  MMD_2025-03-14_M 10320-24_rätt kräva ny anmäla...  \n",
      "4  MMD_2025-04-10_M9265-24_mindre grävning ej väs...  \n",
      "\n",
      "Fullständig, uppdaterad analysrapport sparad till:\n",
      "C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\\data\\02_processed\\pdf_analysis_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Vi konverterar vår lista med resultat till en Pandas DataFrame och kombinerar nya ihop nya och gamla resultat.\n",
    "# Detta gör det superlätt att filtrera, sortera och förstå vad vi har.\n",
    "\n",
    "# Skapa en DataFrame av de NYA resultaten\n",
    "df_new_analysis = pd.DataFrame(new_analysis_results)\n",
    "\n",
    "# Kombinera den gamla (df_existing) med den nya (df_new_analysis)\n",
    "df_combined = pd.concat([df_existing, df_new_analysis], ignore_index=True)\n",
    "\n",
    "# Visa en sammanfattning av den TOTALA rapporten\n",
    "print(\"\\n--- Sammanfattning av TOTAL PDF-analys (Gamla + Nya) ---\")\n",
    "if not df_combined.empty:\n",
    "    status_counts = df_combined['status'].value_counts()\n",
    "    print(status_counts)\n",
    "    print(\"\\n--- Exempel på data (från nya filer om några fanns) ---\")\n",
    "    if not df_new_analysis.empty:\n",
    "        print(df_new_analysis.head())\n",
    "    else:\n",
    "        print(\"Inga nya filer analyserades.\")\n",
    "else:\n",
    "    print(\"Rapporten är tom.\")\n",
    "\n",
    "# Spara den nya, kombinerade rapporten\n",
    "df_combined.to_csv(ANALYSIS_RESULT_FILE, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nFullständig, uppdaterad analysrapport sparad till:\\n{ANALYSIS_RESULT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f316a15",
   "metadata": {},
   "source": [
    "### Hitta en exempelfil som är en OCR-kandidat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64437012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exempel på filer som troligen kräver OCR ---\n",
      "                                              filename  chars_page_1\n",
      "95                          Dnr 502-2025 (ansökan).pdf             0\n",
      "158                            22378-2025 OSL 21-1.pdf             0\n",
      "413  11635-2025 Anmälan för samråd om solcellspark(...            12\n",
      "470                   2076-2025 anmälan och beslut.pdf             0\n",
      "538               Naturvärdesinventering(30759500).pdf            50\n"
     ]
    }
   ],
   "source": [
    "# ## Spot-check av en \"OCR-kandidat\" (Bonus)\n",
    "#\n",
    "# Om du vill *bevisa* att en fil är skannad, behöver vi\n",
    "# biblioteken `pytesseract` och `pdf2image`.\n",
    "#\n",
    "# **OBS:** Detta kräver extern installation!\n",
    "# 1. `pip install pytesseract pdf2image`\n",
    "# 2. Du MÅSTE också installera Googles Tesseract-motor OCH Poppler.\n",
    "#    (På Windows är detta enklast via: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "#     och http://blog.alivate.com.au/poppler-in-windows/)\n",
    "#\n",
    "# **Detta är avancerat, så vi kan vänta med det.** Men det är\n",
    "# här du skulle bekräfta din hypotes.\n",
    "\n",
    "\n",
    "# Hitta en exempelfil som är en OCR-kandidat från den KOMBINERADE rapporten\n",
    "ocr_files = df_combined[df_combined['status'] == 'ocr_candidate'] # Ändrad från df_analysis\n",
    "\n",
    "if not ocr_files.empty:\n",
    "    print(\"\\n--- Exempel på filer som troligen kräver OCR ---\")\n",
    "    print(ocr_files[['filename', 'chars_page_1']].head())\n",
    "else:\n",
    "    print(\"\\nGratulerar! Inga uppenbara OCR-kandidater hittades.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
