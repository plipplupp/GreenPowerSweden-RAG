{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2b1a2a",
   "metadata": {},
   "source": [
    "### Text-extrahering, konverterar alla filer till rena .txt-filer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b31655",
   "metadata": {},
   "source": [
    "##### **Process:**\n",
    "1. Läs `pdf_analysis_report.csv` för att veta vilka PDF:er som är Text vs OCR.\n",
    "2. Definiera en \"worker\"-funktion för varje filtyp.\n",
    "3. Loopa igenom PDF-rapporten och extrahera text från alla PDF:er.\n",
    "4. Loopa igenom övriga filer (`.xlsx`, `.docx` etc.) och extrahera text.\n",
    "5. Spara varje fils extraherade text som en ny `.txt`-fil.\n",
    "   * Dessa sparas i `02_processed/extracted_text/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e685af",
   "metadata": {},
   "source": [
    "### Importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b660c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import docx\n",
    "import email\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from email.parser import BytesParser\n",
    "from email import policy\n",
    "\n",
    "# OCR-specifika importer\n",
    "try:\n",
    "    import pytesseract\n",
    "    from pdf2image import convert_from_path\n",
    "    OCR_ENABLED = True\n",
    "    \n",
    "    # === VIKTIGT PÅ WINDOWS ===\n",
    "    # Om du inte lagt Poppler i din PATH, måste du peka ut var den finns\n",
    "    # t.ex: POPPLER_PATH = r\"C:\\Program Files\\Poppler\\poppler-25.07.0\\Library\\bin\"\n",
    "    POPPLER_PATH = None \n",
    "    \n",
    "    # Om du inte lagt Tesseract i din PATH\n",
    "    # t.ex: pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "except ImportError:\n",
    "    OCR_ENABLED = False\n",
    "    print(\"VARNING: pytesseract eller pdf2image saknas. OCR-extrahering kommer att misslyckas.\")\n",
    "    print(\"Kör 'pip install pytesseract pdf2image' och installera Tesseract/Poppler.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d43377",
   "metadata": {},
   "source": [
    "### Sätt upp sökvägar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8326b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indata från: C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\\data\\01_raw\n",
      "Utdata (text) till: C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\\data\\02_processed\\extracted_text\n",
      "Läser PDF-plan från: C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\\data\\02_processed\\pdf_analysis_report.csv\n",
      "OCR-funktionalitet är: AKTIVERAD\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(r\"C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "CLEAN_DATA_DIR = DATA_DIR / \"01_raw\" # Vår städade indata-mapp\n",
    "PROCESSED_DIR = DATA_DIR / \"02_processed\"\n",
    "\n",
    "# Vår nya mapp för all extraherad text\n",
    "TEXT_OUTPUT_DIR = PROCESSED_DIR / \"extracted_text\"\n",
    "TEXT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sökväg till vår PDF-rapport\n",
    "ANALYSIS_RESULT_FILE = PROCESSED_DIR / \"pdf_analysis_report.csv\"\n",
    "\n",
    "print(f\"Indata från: {CLEAN_DATA_DIR}\")\n",
    "print(f\"Utdata (text) till: {TEXT_OUTPUT_DIR}\")\n",
    "print(f\"Läser PDF-plan från: {ANALYSIS_RESULT_FILE}\")\n",
    "print(f\"OCR-funktionalitet är: {'AKTIVERAD' if OCR_ENABLED else 'AVSTÄNGD'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac7944",
   "metadata": {},
   "source": [
    "### Definiera extraherings-funktioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b51cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar en funktion för varje filtyp för att hålla koden ren.\n",
    "\n",
    "def save_text(original_path: Path, text_content: str, output_dir: Path):\n",
    "    \"\"\"Sparar den extraherade texten till en .txt-fil.\"\"\"\n",
    "    try:\n",
    "        # Skapa ett unikt filnamn, t.ex. \"min_fil.pdf\" -> \"min_fil.pdf.txt\"\n",
    "        output_filename = f\"{original_path.name}.txt\"\n",
    "        output_path = output_dir / output_filename\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text_content)\n",
    "        return \"success\"\n",
    "    except Exception as e:\n",
    "        return f\"error_saving: {e}\"\n",
    "\n",
    "def extract_text_from_text_pdf(file_path: Path) -> tuple[str, str]:\n",
    "    \"\"\"Extraherar text från en digital, textbaserad PDF.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\\n--- Sida Slut ---\\n\\n\"\n",
    "        return text, \"success\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"error_pdfplumber: {e}\"\n",
    "\n",
    "def extract_text_from_ocr_pdf(file_path: Path) -> tuple[str, str]:\n",
    "    \"\"\"Försöker extrahera text från en skannad PDF med OCR.\"\"\"\n",
    "    if not OCR_ENABLED:\n",
    "        return \"\", \"error_ocr_disabled\"\n",
    "    \n",
    "    text = \"\"\n",
    "    try:\n",
    "        # 1. Konvertera PDF till en lista med bilder\n",
    "        # Använd poppler_path om du definierat det\n",
    "        images = convert_from_path(file_path, poppler_path=POPPLER_PATH)\n",
    "        \n",
    "        # 2. Kör OCR på varje bild\n",
    "        for i, img in enumerate(images):\n",
    "            # Använd SVENSKT språkpaket!\n",
    "            page_text = pytesseract.image_to_string(img, lang='swe')\n",
    "            if page_text:\n",
    "                text += page_text + f\"\\n\\n--- Sida {i+1} (OCR) Slut ---\\n\\n\"\n",
    "        \n",
    "        if not text:\n",
    "            return \"\", \"ocr_no_text_found\"\n",
    "            \n",
    "        return text, \"success_ocr\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"error_ocr: {e}\"\n",
    "\n",
    "def extract_text_from_xlsx(file_path: Path) -> tuple[str, str]:\n",
    "    \"\"\"Extraherar text från alla flikar i en Excel-fil.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name, header=None)\n",
    "            text += f\"--- Flik: {sheet_name} ---\\n\"\n",
    "            # Konvertera hela dataframe till en sträng\n",
    "            text += df.to_string(index=False, header=False) + \"\\n\\n\"\n",
    "        return text, \"success\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"error_excel: {e}\"\n",
    "\n",
    "def extract_text_from_docx(file_path: Path) -> tuple[str, str]:\n",
    "    \"\"\"Extraherar text från en Word .docx-fil.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "        return text, \"success\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"error_docx: {e}\"\n",
    "\n",
    "def extract_text_from_html(file_path: Path) -> tuple[str, str]:\n",
    "    \"\"\"Extraherar text från en HTML-fil.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            soup = BeautifulSoup(f, 'html.parser')\n",
    "            text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "        return text, \"success\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"error_html: {e}\"\n",
    "\n",
    "def extract_text_from_eml(file_path: Path) -> tuple[str, str]:\n",
    "    \"\"\"Extraherar textinnehållet från en .eml e-postfil.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            msg = BytesParser(policy=policy.default).parse(f)\n",
    "        \n",
    "        text = \"\"\n",
    "        # Försök få brödtexten\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                if part.get_content_type() == \"text/plain\":\n",
    "                    text += part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "        else:\n",
    "            if msg.get_content_type() == \"text/plain\":\n",
    "                text = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "\n",
    "        if not text: # Fallback\n",
    "             text = msg.get_body(preferencelist=('plain', 'html')).get_content()\n",
    "\n",
    "        return text, \"success\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"error_eml: {e}\"\n",
    "\n",
    "def extract_text_from_txt(file_path: Path) -> tuple[str, str]:\n",
    "    \"\"\"Läser en .txt-fil.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text = f.read()\n",
    "        return text, \"success\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"error_txt: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7e1f9",
   "metadata": {},
   "source": [
    "### Ladda PDF-analysrapporten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6392bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laddade 4502 rader från PDF-rapporten.\n",
      "status\n",
      "text_based       4372\n",
      "ocr_candidate     130\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_analysis = pd.read_csv(ANALYSIS_RESULT_FILE)\n",
    "    print(f\"Laddade {len(df_analysis)} rader från PDF-rapporten.\")\n",
    "    print(df_analysis['status'].value_counts()) # <-- Utskriften du saknade!\n",
    "except FileNotFoundError:\n",
    "    print(f\"FEL: Kunde inte hitta {ANALYSIS_RESULT_FILE}\")\n",
    "    print(\"Se till att du har kört notebook 02 först.\")\n",
    "    df_analysis = pd.DataFrame() # Skapa tom dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e164b9",
   "metadata": {},
   "source": [
    "###  Bearbeta alla PDF-filer - använder rätt funktion (text eller OCR) för varje fil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0126f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Startar bearbetning av PDF-filer (inkrementell)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b6c20285b7460bae6eda6add9cef10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bearbetar PDF:er:   0%|          | 0/4502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P61' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P70' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P74' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P76' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klar med PDF-bearbetning. 3617 filer hoppades över (fanns redan).\n"
     ]
    }
   ],
   "source": [
    "# Laddar filen vi skapade i notebook 02.\n",
    "# Loopar igenom DataFramen, men **hoppar över filer som redan existerar**.\n",
    "\n",
    "pdf_results = []\n",
    "skipped_pdf_count = 0\n",
    "\n",
    "if not df_analysis.empty:\n",
    "    print(\"\\nStartar bearbetning av PDF-filer (inkrementell)...\")\n",
    "    \n",
    "    for _, row in tqdm(df_analysis.iterrows(), total=len(df_analysis), desc=\"Bearbetar PDF:er\"):\n",
    "        file_path = Path(row['full_path'])\n",
    "        status = row['status']\n",
    "        \n",
    "        # --- KONTROLL-STEG ---\n",
    "        output_txt_path = TEXT_OUTPUT_DIR / f\"{file_path.name}.txt\"\n",
    "        if output_txt_path.exists():\n",
    "            pdf_results.append((file_path.name, \"skipped_exists\"))\n",
    "            skipped_pdf_count += 1\n",
    "            continue\n",
    "        # --------------------------\n",
    "            \n",
    "        if not file_path.exists():\n",
    "            pdf_results.append((file_path.name, \"error_file_not_found\"))\n",
    "            continue\n",
    "            \n",
    "        text_content, extract_status = \"\", \"\"\n",
    "        if status == 'text_based':\n",
    "            text_content, extract_status = extract_text_from_text_pdf(file_path)\n",
    "        elif status == 'ocr_candidate':\n",
    "            text_content, extract_status = extract_text_from_ocr_pdf(file_path)\n",
    "        else:\n",
    "            extract_status = f\"skipped_{status}\"\n",
    "            pdf_results.append((file_path.name, extract_status))\n",
    "            continue\n",
    "        \n",
    "        save_status = save_text(file_path, text_content, TEXT_OUTPUT_DIR)\n",
    "        \n",
    "        if save_status == \"success\":\n",
    "            pdf_results.append((file_path.name, extract_status))\n",
    "        else:\n",
    "            pdf_results.append((file_path.name, save_status))\n",
    "\n",
    "    print(f\"Klar med PDF-bearbetning. {skipped_pdf_count} filer hoppades över (fanns redan).\")\n",
    "else:\n",
    "    print(\"\\nHoppar över PDF-bearbetning (ingen rapport hittades eller så var den tom).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb86b6",
   "metadata": {},
   "source": [
    "### Bearbeta övriga filtyper - letar upp alla andra filer vi kan läsa och bearbetar dem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc34f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hittade 131 övriga filer att bearbeta.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21129d54e707472fb9d33be55306d7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bearbetar övriga filer:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klar med bearbetning av övriga filer. 131 filer hoppades över (fanns redan).\n"
     ]
    }
   ],
   "source": [
    "file_types_to_process = ['.xlsx', '.docx', '.html', '.eml', '.txt']\n",
    "other_files = []\n",
    "for ext in file_types_to_process:\n",
    "    other_files.extend(CLEAN_DATA_DIR.rglob(f'*{ext}'))\n",
    "\n",
    "print(f\"\\nHittade {len(other_files)} övriga filer att bearbeta.\")\n",
    "\n",
    "other_results = []\n",
    "skipped_other_count = 0\n",
    "for file_path in tqdm(other_files, desc=\"Bearbetar övriga filer\"):\n",
    "    \n",
    "    # === KONTROLL-STEG ===\n",
    "    output_txt_path = TEXT_OUTPUT_DIR / f\"{file_path.name}.txt\"\n",
    "    if output_txt_path.exists():\n",
    "        other_results.append((file_path.name, \"skipped_exists\"))\n",
    "        skipped_other_count += 1\n",
    "        continue\n",
    "    # ===========================\n",
    "    \n",
    "    ext = file_path.suffix.lower()\n",
    "    text_content, extract_status = \"\", \"\"\n",
    "    \n",
    "    if ext == '.xlsx':\n",
    "        text_content, extract_status = extract_text_from_xlsx(file_path)\n",
    "    elif ext == '.docx':\n",
    "        text_content, extract_status = extract_text_from_docx(file_path)\n",
    "    elif ext == '.html':\n",
    "        text_content, extract_status = extract_text_from_html(file_path)\n",
    "    elif ext == '.eml':\n",
    "        text_content, extract_status = extract_text_from_eml(file_path)\n",
    "    elif ext == '.txt':\n",
    "        text_content, extract_status = extract_text_from_txt(file_path)\n",
    "    \n",
    "    save_status = save_text(file_path, text_content, TEXT_OUTPUT_DIR)\n",
    "    \n",
    "    if save_status == \"success\":\n",
    "        other_results.append((file_path.name, extract_status))\n",
    "    else:\n",
    "        other_results.append((file_path.name, save_status))\n",
    "\n",
    "print(f\"Klar med bearbetning av övriga filer. {skipped_other_count} filer hoppades över (fanns redan).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f0e7d",
   "metadata": {},
   "source": [
    "### Slutsummering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e940bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Summering PDF-bearbetning ---\n",
      "status\n",
      "skipped_exists                                                                                           3617\n",
      "success                                                                                                   862\n",
      "error_ocr: tesseract is not installed or it's not in your PATH. See README file for more information.      23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Summering Övriga filer ---\n",
      "status\n",
      "skipped_exists    131\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Total inventering på disk ---\n",
      "Totala antalet textfiler skapade i C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\\data\\02_processed\\extracted_text:\n",
      "4483\n"
     ]
    }
   ],
   "source": [
    "# Den här cellen kan du nu köra om och om igen. Den enda importen den behöver är `pandas`, som importera IGEN här, för säkerhets skull.\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Definiera sökvägar igen (ifall kerneln startats om)\n",
    "BASE_DIR = Path(r\"C:\\Users\\Dator\\Documents\\Data_Science\\11_Examensarbete\\green_power_sweden\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"02_processed\"\n",
    "TEXT_OUTPUT_DIR = PROCESSED_DIR / \"extracted_text\"\n",
    "\n",
    "print(\"--- Summering PDF-bearbetning ---\")\n",
    "if 'pdf_results' in locals():\n",
    "    # Om vi körde allt nu, visa den nya rapporten\n",
    "    df_pdf_res = pd.DataFrame(pdf_results, columns=['filename', 'status'])\n",
    "    print(df_pdf_res['status'].value_counts())\n",
    "else:\n",
    "    # Om kerneln startats om, visa bara en notis\n",
    "    print(\"('pdf_results' finns ej i minnet, visar totalt antal filer istället)\")\n",
    "\n",
    "print(\"\\n--- Summering Övriga filer ---\")\n",
    "if 'other_results' in locals():\n",
    "    # Om vi körde allt nu, visa den nya rapporten\n",
    "    df_other_res = pd.DataFrame(other_results, columns=['filename', 'status'])\n",
    "    print(df_other_res['status'].value_counts())\n",
    "else:\n",
    "    # Om kerneln startats om, visa bara en notis\n",
    "    print(\"('other_results' finns ej i minnet, visar totalt antal filer istället)\")\n",
    "\n",
    "\n",
    "print(f\"\\n--- Total inventering på disk ---\")\n",
    "print(f\"Totala antalet textfiler skapade i {TEXT_OUTPUT_DIR}:\")\n",
    "total_txt_files = len(list(TEXT_OUTPUT_DIR.glob('*.*.txt'))) # Säkrare räkning\n",
    "print(total_txt_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
